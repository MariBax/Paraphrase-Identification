{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariya.bakhanova\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import bimpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bimpm.py\n",
    "%run text_processing_rv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model UDP...\n"
     ]
    }
   ],
   "source": [
    "# URL of the UDPipe model\n",
    "udpipe_model_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
    "udpipe_filename = udpipe_model_url.split('/')[-1]\n",
    "\n",
    "if not os.path.isfile(udpipe_filename):\n",
    "    print('UDPipe model not found. Downloading...', file=sys.stderr)\n",
    "    wget.download(udpipe_model_url)\n",
    "\n",
    "print('\\nLoading the model UDP...', file=sys.stderr)\n",
    "model = Model.load(udpipe_filename)\n",
    "process_pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word2vec embeddings:\n",
      "Saving word2idx to: cache\\word2idx.pkl\n",
      "Done!\n",
      "Saving word2vec embeddings to: cache\\bimpm.pkl\n",
      "Done!\n",
      "8214 300\n",
      "Shape of word2vec embeddings: (8214, 300)\n",
      "Max_train: 11 13\n",
      "(1910, 13) (1910, 13) (1910,)\n",
      "Max_test: 11 11\n",
      "(942, 13) (942, 13) (942,)\n"
     ]
    }
   ],
   "source": [
    "x = My_model()\n",
    "x.sen_len = 13\n",
    "x.load_w2v()\n",
    "\n",
    "x.sentence_one,x.sentence_two,x.y_true = load_dataset(x.dataset_path_train,x.word2idx,model, process_pipeline)\n",
    "x.sentence_one_test,x.sentence_two_test,x.y_true_test = load_dataset_test(x.dataset_path_test,x.word2idx,model,process_pipeline)\n",
    "# exit(0)\n",
    "dropout_rate = 0.1\n",
    "num_epoch = 2\n",
    "batch_size = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sentence_one_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_init = tf.placeholder(tf.float32, shape=(x.vocab_size, x.embed_dim)) # (vocab_size, 300)\n",
    "\n",
    "sentence_one = tf.placeholder(\"int32\",[batch_size, x.sen_len],name=\"sentence_one\")\n",
    "sentence_two = tf.placeholder(\"int32\",[batch_size, x.sen_len],name=\"sentence_two\")\n",
    "\n",
    "Y = tf.placeholder(\"int32\",[batch_size, 2],name=\"true_labels\")\n",
    "\n",
    "embedding_weights = tf.get_variable( # variable\n",
    "    name = 'embedding_weights',\n",
    "    initializer = X_init,\n",
    "    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Word_embeddings\"):\n",
    "    \n",
    "    # nn - module for constructing rnn cells\n",
    "    # embedding_lookup - looks up ids in a list of embedding tensors.\n",
    "    embedded_sentence_one = tf.nn.embedding_lookup(embedding_weights,sentence_one)\n",
    "    embedded_sentence_two = tf.nn.embedding_lookup(embedding_weights,sentence_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mariya.bakhanova\\DIPLOMA\\Paraphrase-detection-master\\Code for Paraphrase identification\\Paraphrase identification\\matching.py:157: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Context_representation_layer\"):\n",
    "\n",
    "    context_rnn_hidden_size = 100\n",
    "\n",
    "    sentence_enc_fw = tf.nn.rnn_cell.LSTMCell(context_rnn_hidden_size, state_is_tuple=True)\n",
    "    sentence_enc_bw = tf.nn.rnn_cell.LSTMCell(context_rnn_hidden_size, state_is_tuple=True)\n",
    "\n",
    "    # Sentence 1\n",
    "    # Shape (batch_size, sequence_length, rnn_hidden_size)\n",
    "\n",
    "    outputs_1, states_1  = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=sentence_enc_fw,\n",
    "        cell_bw=sentence_enc_bw,\n",
    "        dtype=tf.float32,\n",
    "        # sequence_length=length(sentence_one),\n",
    "        inputs=embedded_sentence_one)\n",
    "\n",
    "    output_fw_1, output_bw_1 = outputs_1\n",
    "    states_fw_1, states_bw_1 = states_1\n",
    "\n",
    "    output_fw_1 = tf.layers.dropout(\n",
    "        output_fw_1,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"sentence_1_fw_dropout\")\n",
    "    output_bw_1 = tf.layers.dropout(\n",
    "        output_bw_1,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"sentence_1_bw_dropout\")\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    #Sentence 2\n",
    "\n",
    "    # Shape (batch_size, sequence_length, rnn_hidden_size)\n",
    "\n",
    "    outputs_2, states_2  = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=sentence_enc_fw,\n",
    "        cell_bw=sentence_enc_bw,\n",
    "        dtype=tf.float32,\n",
    "        # sequence_length=length(sentence_two),\n",
    "        inputs=embedded_sentence_two)\n",
    "\n",
    "    output_fw_2, output_bw_2 = outputs_2\n",
    "    states_fw_2, states_bw_2 = states_2\n",
    "\n",
    "    output_fw_2 = tf.layers.dropout(\n",
    "        output_fw_2,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"sentence_2_fw_dropout\")\n",
    "    output_bw_2 = tf.layers.dropout(\n",
    "        output_bw_2,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"sentence_2_bw_dropout\")\n",
    "\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "with tf.variable_scope(\"Matching_layer\"):\n",
    "\n",
    "    # Shape (batch_size, sequence_length, 8*perspectives)\n",
    "\n",
    "    match_1_2, match_2_1 = bidirectional_match(output_fw_1,output_bw_1,output_fw_2,output_bw_2)\n",
    "\n",
    "    match_1_2 = tf.layers.dropout(\n",
    "        match_1_2,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"match_1_2_dropout\")\n",
    "    match_2_1 = tf.layers.dropout(\n",
    "        match_2_1,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"match_2_1_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregation Layer\n",
    "\n",
    "with tf.variable_scope(\"Aggregation_layer\"):\n",
    "\n",
    "    agg_last = []\n",
    "\n",
    "    # Sentence 1\n",
    "\n",
    "    with tf.variable_scope(\"agg_1\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "        aggregation_enc_fw = tf.nn.rnn_cell.LSTMCell(context_rnn_hidden_size,state_is_tuple=True)\n",
    "        aggregation_enc_bw = tf.nn.rnn_cell.LSTMCell(context_rnn_hidden_size,state_is_tuple=True)\t\n",
    "\n",
    "        # Shape (batch_size, sequence_length, rnn_hidden_size)\n",
    "\n",
    "\n",
    "        agg_outputs_1, agg_states_1  = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=aggregation_enc_fw,\n",
    "            cell_bw=aggregation_enc_bw,\n",
    "            dtype=tf.float32,\n",
    "            # sequence_length=length(sentence_one),\n",
    "            inputs=match_1_2)\n",
    "\n",
    "        agg_output_fw_1, agg_output_bw_1 = agg_outputs_1\n",
    "\n",
    "        agg_output_fw_1 = tf.layers.dropout(\n",
    "            agg_output_fw_1,\n",
    "            rate=dropout_rate,\n",
    "            training=False,\n",
    "            name=\"agg_1_fw_dropout\")\n",
    "        agg_output_bw_1 = tf.layers.dropout(\n",
    "            agg_output_bw_1,\n",
    "            rate=dropout_rate,\n",
    "            training=False,\n",
    "            name=\"agg_1_bw_dropout\")\n",
    "\n",
    "        # Shape : (batch_size, rnn_hidden_size)\n",
    "\n",
    "        agg_output_fw_1_last = get_last_output(agg_output_fw_1)\n",
    "        agg_output_bw_1_last = get_last_output(agg_output_bw_1)\n",
    "\n",
    "        agg_last.append(agg_output_fw_1_last)\n",
    "        agg_last.append(agg_output_bw_1_last)\n",
    "\n",
    "    #tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    #Sentence 2\n",
    "\n",
    "    with tf.variable_scope(\"agg_2\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "        aggregation_enc_fw_2 = tf.nn.rnn_cell.LSTMCell(context_rnn_hidden_size,state_is_tuple=True)\n",
    "        aggregation_enc_bw_2 = tf.nn.rnn_cell.LSTMCell(context_rnn_hidden_size,state_is_tuple=True)\n",
    "\n",
    "        # Shape (batch_size, sequence_length, rnn_hidden_size)\n",
    "\n",
    "        agg_outputs_2, agg_states_2  = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=aggregation_enc_fw_2,\n",
    "            cell_bw=aggregation_enc_bw_2,\n",
    "            dtype=tf.float32,\n",
    "            # sequence_length=length(sentence_two),\n",
    "            inputs=match_2_1)\n",
    "\n",
    "        agg_output_fw_2, agg_output_bw_2 = agg_outputs_2\n",
    "\n",
    "        agg_output_fw_2 = tf.layers.dropout(\n",
    "            agg_output_fw_2,\n",
    "            rate=dropout_rate,\n",
    "            training=False,\n",
    "            name=\"agg_2_fw_dropout\")\n",
    "        agg_output_bw_2 = tf.layers.dropout(\n",
    "            agg_output_bw_2,\n",
    "            rate=dropout_rate,\n",
    "            training=False,\n",
    "            name=\"agg_2_bw_dropout\")\n",
    "\n",
    "\n",
    "        # Shape : (batch_size, rnn_hidden_size)\n",
    "\n",
    "        agg_output_fw_2_last = get_last_output(agg_output_fw_2)\n",
    "        agg_output_bw_2_last = get_last_output(agg_output_bw_2)\n",
    "\n",
    "\n",
    "        agg_last.append(agg_output_fw_2_last)\n",
    "        agg_last.append(agg_output_bw_2_last)\n",
    "\n",
    "    # Shape : (batch_size, 4*rnn_hidden_size)\n",
    "\n",
    "    combined_agg_last = tf.concat(agg_last,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-da018d9428fa>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Prediction Layer\n",
    "with tf.variable_scope(\"Prediction_layer\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "    prediction_layer_1 = tf.layers.dense(combined_agg_last,\n",
    "        combined_agg_last.get_shape().as_list()[1],\n",
    "        activation=tf.nn.tanh,\n",
    "        name=\"pred_1\")\n",
    "\n",
    "    prediction_layer_1 = tf.layers.dropout(\n",
    "        prediction_layer_1,\n",
    "        rate=dropout_rate,\n",
    "        training=False,\n",
    "        name=\"pred_dropout\")\n",
    "\n",
    "    prediction_layer_2 = tf.layers.dense(prediction_layer_1,2,name=\"pred_2\")\n",
    "\n",
    "with tf.variable_scope(\"Train_loss_and_acc\", reuse=tf.AUTO_REUSE):\n",
    "\n",
    "    y_pred = tf.nn.softmax(prediction_layer_2)\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=prediction_layer_2))\n",
    "\n",
    "    tf.summary.scalar('loss',loss_op)\n",
    "\n",
    "    correct_predictions = tf.equal(tf.argmax(y_pred, 1),tf.argmax(Y, 1))\n",
    "#     correct_positive = (tf.equal(tf.equal(tf.argmax(y_pred, 1),tf.argmax(Y, 1)), tf.cast(tf.ones(batch_size), 'bool')))\n",
    "    y_pred_argmax = tf.argmax(y_pred, 1)\n",
    "    y_true_argmax = tf.argmax(Y, 1)\n",
    "    TP = tf.count_nonzero(y_pred_argmax * y_true_argmax, dtype=tf.float32)\n",
    "    TN = tf.count_nonzero((y_pred_argmax - 1) * (y_true_argmax - 1), dtype=tf.float32)\n",
    "    FP = tf.count_nonzero(y_pred_argmax * (y_true_argmax - 1), dtype=tf.float32)\n",
    "    FN = tf.count_nonzero((y_pred_argmax - 1) * y_true_argmax, dtype=tf.float32)\n",
    "    \n",
    "    batch_accuracy = tf.reduce_mean(tf.cast(correct_predictions,\"float\"))\n",
    "#     precision_numerator = tf.reduce_mean(tf.cast(correct_positive,\"float\"))\n",
    "    \n",
    "#     batch_precision = tf.metrics.precision(Y, y_pred)\n",
    "#     batch_recall = tf.metrics.recall(Y, y_pred)\n",
    "#     batch_f1_score = tf.reduce_mean(tf.divide(tf.multiply(tf.cast(2, \"float\"), tf.multiply(batch_recall, batch_precision)), tf.reduce_sum(batch_precision, batch_recall)))\n",
    "    tf.summary.scalar('accuracy',batch_accuracy)\n",
    "#     tf.summary.scalar('precision_numerator',precision_numerator)\n",
    "#     tf.summary.scalar('precision',batch_precision)\n",
    "#     tf.summary.scalar('recall',batch_recall)\n",
    "#     tf.summary.scalar('f1_score',batch_f1_score)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=x.learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, )\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", shape=(314,), dtype=int64)\n",
      "Tensor(\"Train_loss_and_acc/Softmax:0\", shape=(314, 2), dtype=float32)\n",
      "Tensor(\"Equal:0\", shape=(314,), dtype=bool)\n",
      "Tensor(\"count_nonzero/Sum:0\", shape=(), dtype=int64)\n",
      "Tensor(\"Equal_2:0\", shape=(314,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(tf.argmax(y_pred, 1))\n",
    "print(y_pred)\n",
    "print(tf.equal(tf.argmax(y_pred, 1),tf.argmax(Y, 1)))\n",
    "print(tf.count_nonzero(tf.argmax(y_pred, 1) * tf.argmax(Y, 1)))\n",
    "print(tf.equal(tf.equal(tf.argmax(y_pred, 1),tf.argmax(Y, 1)), tf.cast(tf.ones(batch_size), 'bool')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]C:\\Users\\mariya.bakhanova\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in float_scalars\n",
      "C:\\Users\\mariya.bakhanova\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 0.0  TN: 162.0  FP: 0.0  FN: 152.0  Precision: nan  Recall: 0.0  F1-score: nan\n",
      "OVERALL TP: 0.0  TN: 162.0  FP: 0.0  FN: 152.0  Precision: nan  Recall: 0.0  F1-score: nan\n",
      "Epoch:1 Step:0 Loss:0.7029 Batch Acc:0.5159 Mean Batch Acc:0.5159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:38<03:14, 38.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 139.0  TN: 0.0  FP: 175.0  FN: 0.0  Precision: 0.44267517  Recall: 1.0  F1-score: 0.6136865730691926\n",
      "OVERALL TP: 139.0  TN: 162.0  FP: 175.0  FN: 152.0  Precision: 0.4426751592356688  Recall: 0.47766323024054985  F1-score: 0.4595041322314049\n",
      "Epoch:1 Step:1 Loss:0.7086 Batch Acc:0.4427 Mean Batch Acc:0.4793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:12<02:29, 37.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 167.0  TN: 8.0  FP: 137.0  FN: 2.0  Precision: 0.5493421  Recall: 0.9881657  F1-score: 0.7061310694585323\n",
      "OVERALL TP: 306.0  TN: 170.0  FP: 312.0  FN: 154.0  Precision: 0.49514563106796117  Recall: 0.6652173913043479  F1-score: 0.5677179962894249\n",
      "Epoch:1 Step:2 Loss:0.6857 Batch Acc:0.5573 Mean Batch Acc:0.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:48<01:50, 36.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 144.0  TN: 61.0  FP: 96.0  FN: 13.0  Precision: 0.6  Recall: 0.91719747  F1-score: 0.7254408277468477\n",
      "OVERALL TP: 450.0  TN: 231.0  FP: 408.0  FN: 167.0  Precision: 0.5244755244755245  Recall: 0.7293354943273906  F1-score: 0.6101694915254239\n",
      "Epoch:1 Step:3 Loss:0.6822 Batch Acc:0.6529 Mean Batch Acc:0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:25<01:14, 37.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 145.0  TN: 97.0  FP: 48.0  FN: 24.0  Precision: 0.7512953  Recall: 0.8579882  F1-score: 0.8011050028193447\n",
      "OVERALL TP: 595.0  TN: 328.0  FP: 456.0  FN: 191.0  Precision: 0.566127497621313  Recall: 0.7569974554707379  F1-score: 0.647795318454001\n",
      "Epoch:1 Step:4 Loss:0.6763 Batch Acc:0.7707 Mean Batch Acc:0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:56<00:35, 35.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 124.0  TN: 63.0  FP: 115.0  FN: 12.0  Precision: 0.51882845  Recall: 0.9117647  F1-score: 0.6613333266745672\n",
      "OVERALL TP: 719.0  TN: 391.0  FP: 571.0  FN: 203.0  Precision: 0.5573643410852713  Recall: 0.779826464208243  F1-score: 0.6500904159132008\n",
      "Epoch:1 Step:5 Loss:0.6768 Batch Acc:0.5955 Mean Batch Acc:0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▏                                                                         | 1/10 [03:30<31:37, 210.88s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 123.0  TN: 127.0  FP: 35.0  FN: 29.0  Precision: 0.778481  Recall: 0.80921054  F1-score: 0.7935483899945149\n",
      "OVERALL TP: 842.0  TN: 518.0  FP: 606.0  FN: 232.0  Precision: 0.5814917127071824  Recall: 0.7839851024208566  F1-score: 0.6677240285487709\n",
      "Epoch:2 Step:0 Loss:0.6659 Batch Acc:0.7962 Mean Batch Acc:0.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:35<02:55, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 59.0  TN: 166.0  FP: 9.0  FN: 80.0  Precision: 0.86764705  Recall: 0.42446044  F1-score: 0.5700483291276395\n",
      "OVERALL TP: 901.0  TN: 684.0  FP: 615.0  FN: 312.0  Precision: 0.5943271767810027  Recall: 0.7427864798021434  F1-score: 0.6603151337486258\n",
      "Epoch:2 Step:1 Loss:0.6583 Batch Acc:0.7166 Mean Batch Acc:0.6310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:11<02:21, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 1.0  TN: 145.0  FP: 0.0  FN: 168.0  Precision: 1.0  Recall: 0.00591716  F1-score: 0.011764705664507252\n",
      "OVERALL TP: 902.0  TN: 829.0  FP: 615.0  FN: 480.0  Precision: 0.5945945945945946  Recall: 0.6526772793053546  F1-score: 0.6222835460503622\n",
      "Epoch:2 Step:2 Loss:0.6768 Batch Acc:0.4650 Mean Batch Acc:0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:47<01:46, 35.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 38.0  TN: 149.0  FP: 8.0  FN: 119.0  Precision: 0.82608694  Recall: 0.24203822  F1-score: 0.3743842493507398\n",
      "OVERALL TP: 940.0  TN: 978.0  FP: 623.0  FN: 599.0  Precision: 0.6014075495841331  Recall: 0.6107862248213125  F1-score: 0.6060606060606061\n",
      "Epoch:2 Step:3 Loss:0.6500 Batch Acc:0.5955 Mean Batch Acc:0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:20<01:09, 34.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 143.0  TN: 109.0  FP: 36.0  FN: 26.0  Precision: 0.79888266  Recall: 0.84615386  F1-score: 0.821839104871767\n",
      "OVERALL TP: 1083.0  TN: 1087.0  FP: 659.0  FN: 625.0  Precision: 0.621699196326062  Recall: 0.6340749414519906  F1-score: 0.6278260869565216\n",
      "Epoch:2 Step:4 Loss:0.6378 Batch Acc:0.8025 Mean Batch Acc:0.6283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:56<00:35, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 121.0  TN: 75.0  FP: 103.0  FN: 15.0  Precision: 0.5401786  Recall: 0.8897059  F1-score: 0.6722222740267542\n",
      "OVERALL TP: 1204.0  TN: 1162.0  FP: 762.0  FN: 640.0  Precision: 0.612410986775178  Recall: 0.6529284164859002  F1-score: 0.632020997375328\n",
      "Epoch:2 Step:5 Loss:0.6466 Batch Acc:0.6242 Mean Batch Acc:0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▍                                                                 | 2/10 [07:02<28:07, 210.98s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 141.0  TN: 73.0  FP: 89.0  FN: 11.0  Precision: 0.6130435  Recall: 0.92763156  F1-score: 0.7382198947226443\n",
      "OVERALL TP: 1345.0  TN: 1235.0  FP: 851.0  FN: 651.0  Precision: 0.6124772313296903  Recall: 0.6738476953907816  F1-score: 0.6416984732824428\n",
      "Epoch:3 Step:0 Loss:0.6310 Batch Acc:0.6815 Mean Batch Acc:0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:33<02:49, 33.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 121.0  TN: 87.0  FP: 88.0  FN: 18.0  Precision: 0.57894737  Recall: 0.8705036  F1-score: 0.6954022989135734\n",
      "OVERALL TP: 1466.0  TN: 1322.0  FP: 939.0  FN: 669.0  Precision: 0.6095634095634096  Recall: 0.6866510538641686  F1-score: 0.6458149779735683\n",
      "Epoch:3 Step:1 Loss:0.6314 Batch Acc:0.6624 Mean Batch Acc:0.6342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:06<02:13, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 137.0  TN: 83.0  FP: 62.0  FN: 32.0  Precision: 0.68844223  Recall: 0.8106509  F1-score: 0.7445652571652933\n",
      "OVERALL TP: 1603.0  TN: 1405.0  FP: 1001.0  FN: 701.0  Precision: 0.6155913978494624  Recall: 0.6957465277777778  F1-score: 0.6532192339038304\n",
      "Epoch:3 Step:2 Loss:0.6311 Batch Acc:0.7006 Mean Batch Acc:0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:40<01:40, 33.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 125.0  TN: 116.0  FP: 41.0  FN: 32.0  Precision: 0.75301206  Recall: 0.79617834  F1-score: 0.7739938134427421\n",
      "OVERALL TP: 1728.0  TN: 1521.0  FP: 1042.0  FN: 733.0  Precision: 0.623826714801444  Recall: 0.7021535960991467  F1-score: 0.6606767348499332\n",
      "Epoch:3 Step:3 Loss:0.6023 Batch Acc:0.7675 Mean Batch Acc:0.6467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:14<01:07, 33.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 143.0  TN: 111.0  FP: 34.0  FN: 26.0  Precision: 0.8079096  Recall: 0.84615386  F1-score: 0.8265896015136328\n",
      "OVERALL TP: 1871.0  TN: 1632.0  FP: 1076.0  FN: 759.0  Precision: 0.6348829317950458  Recall: 0.7114068441064639  F1-score: 0.6709700555854403\n",
      "Epoch:3 Step:4 Loss:0.5894 Batch Acc:0.8089 Mean Batch Acc:0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:49<00:34, 34.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 111.0  TN: 117.0  FP: 61.0  FN: 25.0  Precision: 0.64534885  Recall: 0.8161765  F1-score: 0.7207792281983855\n",
      "OVERALL TP: 1982.0  TN: 1749.0  FP: 1137.0  FN: 784.0  Precision: 0.6354600833600513  Recall: 0.7165582067968185  F1-score: 0.6735768903993203\n",
      "Epoch:3 Step:5 Loss:0.5928 Batch Acc:0.7261 Mean Batch Acc:0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▌                                                         | 3/10 [10:27<24:25, 209.41s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 130.0  TN: 119.0  FP: 43.0  FN: 22.0  Precision: 0.7514451  Recall: 0.8552632  F1-score: 0.8000000226771337\n",
      "OVERALL TP: 2112.0  TN: 1868.0  FP: 1180.0  FN: 806.0  Precision: 0.6415552855407047  Recall: 0.7237834132967786  F1-score: 0.6801932367149758\n",
      "Epoch:4 Step:0 Loss:0.5760 Batch Acc:0.7930 Mean Batch Acc:0.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:37<03:09, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 114.0  TN: 122.0  FP: 53.0  FN: 25.0  Precision: 0.6826347  Recall: 0.8201439  F1-score: 0.7450980546330962\n",
      "OVERALL TP: 2226.0  TN: 1990.0  FP: 1233.0  FN: 831.0  Precision: 0.6435385949696444  Recall: 0.7281648675171737  F1-score: 0.6832412523020257\n",
      "Epoch:4 Step:1 Loss:0.5735 Batch Acc:0.7516 Mean Batch Acc:0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:14<02:29, 37.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 130.0  TN: 101.0  FP: 44.0  FN: 39.0  Precision: 0.74712646  Recall: 0.7692308  F1-score: 0.7580175411746912\n",
      "OVERALL TP: 2356.0  TN: 2091.0  FP: 1277.0  FN: 870.0  Precision: 0.6484998623726947  Recall: 0.7303161810291382  F1-score: 0.6869806094182827\n",
      "Epoch:4 Step:2 Loss:0.5976 Batch Acc:0.7357 Mean Batch Acc:0.6744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:47<01:48, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 125.0  TN: 116.0  FP: 41.0  FN: 32.0  Precision: 0.75301206  Recall: 0.79617834  F1-score: 0.7739938134427421\n",
      "OVERALL TP: 2481.0  TN: 2207.0  FP: 1318.0  FN: 902.0  Precision: 0.653066596472756  Recall: 0.733372746083358  F1-score: 0.6908939014202173\n",
      "Epoch:4 Step:3 Loss:0.5517 Batch Acc:0.7675 Mean Batch Acc:0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:22<01:11, 35.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 145.0  TN: 103.0  FP: 42.0  FN: 24.0  Precision: 0.77540106  Recall: 0.8579882  F1-score: 0.8146067398912208\n",
      "OVERALL TP: 2626.0  TN: 2310.0  FP: 1360.0  FN: 926.0  Precision: 0.6588058203712995  Recall: 0.7393018018018018  F1-score: 0.6967365348898912\n",
      "Epoch:4 Step:4 Loss:0.5228 Batch Acc:0.7898 Mean Batch Acc:0.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:55<00:34, 34.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 115.0  TN: 111.0  FP: 67.0  FN: 21.0  Precision: 0.6318681  Recall: 0.8455882  F1-score: 0.7232704248417404\n",
      "OVERALL TP: 2741.0  TN: 2421.0  FP: 1427.0  FN: 947.0  Precision: 0.6576295585412668  Recall: 0.7432212581344902  F1-score: 0.6978105906313646\n",
      "Epoch:4 Step:5 Loss:0.5554 Batch Acc:0.7197 Mean Batch Acc:0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████████████████████████████████▊                                                 | 4/10 [13:55<20:53, 208.97s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 133.0  TN: 108.0  FP: 54.0  FN: 19.0  Precision: 0.7112299  Recall: 0.875  F1-score: 0.7846607510554617\n",
      "OVERALL TP: 2874.0  TN: 2529.0  FP: 1481.0  FN: 966.0  Precision: 0.6599311136624569  Recall: 0.7484375  F1-score: 0.7014032946918853\n",
      "Epoch:5 Step:0 Loss:0.5217 Batch Acc:0.7675 Mean Batch Acc:0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:32<02:44, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 115.0  TN: 116.0  FP: 59.0  FN: 24.0  Precision: 0.66091955  Recall: 0.82733816  F1-score: 0.7348243264847104\n",
      "OVERALL TP: 2989.0  TN: 2645.0  FP: 1540.0  FN: 990.0  Precision: 0.6599690880989181  Recall: 0.7511937672782106  F1-score: 0.7026328161730137\n",
      "Epoch:5 Step:1 Loss:0.5259 Batch Acc:0.7357 Mean Batch Acc:0.6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:06<02:12, 33.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 131.0  TN: 100.0  FP: 45.0  FN: 38.0  Precision: 0.7443182  Recall: 0.7751479  F1-score: 0.7594202561149135\n",
      "OVERALL TP: 3120.0  TN: 2745.0  FP: 1585.0  FN: 1028.0  Precision: 0.6631243358129649  Recall: 0.7521697203471552  F1-score: 0.7048458149779735\n",
      "Epoch:5 Step:2 Loss:0.5546 Batch Acc:0.7357 Mean Batch Acc:0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:40<01:39, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 122.0  TN: 120.0  FP: 37.0  FN: 35.0  Precision: 0.7672956  Recall: 0.77707005  F1-score: 0.7721518904968744\n",
      "OVERALL TP: 3242.0  TN: 2865.0  FP: 1622.0  FN: 1063.0  Precision: 0.6665296052631579  Recall: 0.7530778164924506  F1-score: 0.7071654487948521\n",
      "Epoch:5 Step:3 Loss:0.5097 Batch Acc:0.7707 Mean Batch Acc:0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:11<01:05, 32.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 145.0  TN: 112.0  FP: 33.0  FN: 24.0  Precision: 0.8146067  Recall: 0.8579882  F1-score: 0.8357348684012823\n",
      "OVERALL TP: 3387.0  TN: 2977.0  FP: 1655.0  FN: 1087.0  Precision: 0.6717572391907973  Recall: 0.7570406794814484  F1-score: 0.7118537200504415\n",
      "Epoch:5 Step:4 Loss:0.4671 Batch Acc:0.8185 Mean Batch Acc:0.6989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [02:42<00:32, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 112.0  TN: 124.0  FP: 54.0  FN: 24.0  Precision: 0.67469877  Recall: 0.8235294  F1-score: 0.7417218433828247\n",
      "OVERALL TP: 3499.0  TN: 3101.0  FP: 1709.0  FN: 1111.0  Precision: 0.6718509984639017  Recall: 0.7590021691973969  F1-score: 0.7127724587492361\n",
      "Epoch:5 Step:5 Loss:0.5030 Batch Acc:0.7516 Mean Batch Acc:0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████                                         | 5/10 [17:12<17:06, 205.35s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 131.0  TN: 119.0  FP: 43.0  FN: 21.0  Precision: 0.75287354  Recall: 0.8618421  F1-score: 0.8036809938978471\n",
      "OVERALL TP: 3630.0  TN: 3220.0  FP: 1752.0  FN: 1132.0  Precision: 0.6744704570791528  Recall: 0.7622847543049139  F1-score: 0.7156940063091483\n",
      "Epoch:6 Step:0 Loss:0.4694 Batch Acc:0.7962 Mean Batch Acc:0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:35<02:55, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 116.0  TN: 124.0  FP: 51.0  FN: 23.0  Precision: 0.6946108  Recall: 0.8345324  F1-score: 0.7581699643320854\n",
      "OVERALL TP: 3746.0  TN: 3344.0  FP: 1803.0  FN: 1155.0  Precision: 0.6750765903766445  Recall: 0.7643338094266476  F1-score: 0.7169377990430622\n",
      "Epoch:6 Step:1 Loss:0.4779 Batch Acc:0.7643 Mean Batch Acc:0.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:11<02:21, 35.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 132.0  TN: 103.0  FP: 42.0  FN: 37.0  Precision: 0.7586207  Recall: 0.7810651  F1-score: 0.7696793333603726\n",
      "OVERALL TP: 3878.0  TN: 3447.0  FP: 1845.0  FN: 1192.0  Precision: 0.6776166346321859  Recall: 0.7648915187376726  F1-score: 0.718613916427314\n",
      "Epoch:6 Step:2 Loss:0.5091 Batch Acc:0.7484 Mean Batch Acc:0.7069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:48<01:47, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 127.0  TN: 120.0  FP: 37.0  FN: 30.0  Precision: 0.7743902  Recall: 0.8089172  F1-score: 0.7912772295319775\n",
      "OVERALL TP: 4005.0  TN: 3567.0  FP: 1882.0  FN: 1222.0  Precision: 0.6803125530830644  Recall: 0.7662138894203175  F1-score: 0.7207126147201728\n",
      "Epoch:6 Step:3 Loss:0.4732 Batch Acc:0.7866 Mean Batch Acc:0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:23<01:11, 35.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 146.0  TN: 110.0  FP: 35.0  FN: 23.0  Precision: 0.80662984  Recall: 0.8639053  F1-score: 0.8342857383786425\n",
      "OVERALL TP: 4151.0  TN: 3677.0  FP: 1917.0  FN: 1245.0  Precision: 0.6840804218852999  Recall: 0.7692735359525574  F1-score: 0.7241800418702024\n",
      "Epoch:6 Step:4 Loss:0.4115 Batch Acc:0.8153 Mean Batch Acc:0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [03:03<00:36, 36.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 119.0  TN: 125.0  FP: 53.0  FN: 17.0  Precision: 0.69186044  Recall: 0.875  F1-score: 0.7727272554359941\n",
      "OVERALL TP: 4270.0  TN: 3802.0  FP: 1970.0  FN: 1262.0  Precision: 0.6842948717948718  Recall: 0.7718727404193781  F1-score: 0.7254502208630649\n",
      "Epoch:6 Step:5 Loss:0.4709 Batch Acc:0.7771 Mean Batch Acc:0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [20:55<14:02, 210.69s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 127.0  TN: 123.0  FP: 39.0  FN: 25.0  Precision: 0.76506025  Recall: 0.8355263  F1-score: 0.7987421282031555\n",
      "OVERALL TP: 4397.0  TN: 3925.0  FP: 2009.0  FN: 1287.0  Precision: 0.6863877614736185  Recall: 0.7735749472202674  F1-score: 0.7273779983457404\n",
      "Epoch:7 Step:0 Loss:0.4324 Batch Acc:0.7962 Mean Batch Acc:0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:38<03:10, 38.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 116.0  TN: 134.0  FP: 41.0  FN: 23.0  Precision: 0.7388535  Recall: 0.8345324  F1-score: 0.7837837629341324\n",
      "OVERALL TP: 4513.0  TN: 4059.0  FP: 2050.0  FN: 1310.0  Precision: 0.6876428462593326  Recall: 0.775030053237163  F1-score: 0.7287259809462296\n",
      "Epoch:7 Step:1 Loss:0.4386 Batch Acc:0.7962 Mean Batch Acc:0.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:13<02:29, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 126.0  TN: 111.0  FP: 34.0  FN: 43.0  Precision: 0.7875  Recall: 0.74556214  F1-score: 0.7659574314702593\n",
      "OVERALL TP: 4639.0  TN: 4170.0  FP: 2084.0  FN: 1353.0  Precision: 0.6900193366056819  Recall: 0.7741989319092123  F1-score: 0.7296893432953205\n",
      "Epoch:7 Step:2 Loss:0.4712 Batch Acc:0.7548 Mean Batch Acc:0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:51<01:52, 37.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 128.0  TN: 126.0  FP: 31.0  FN: 29.0  Precision: 0.8050314  Recall: 0.81528664  F1-score: 0.8101265742298002\n",
      "OVERALL TP: 4767.0  TN: 4296.0  FP: 2115.0  FN: 1382.0  Precision: 0.6926765475152572  Recall: 0.7752480078061473  F1-score: 0.7316399355383318\n",
      "Epoch:7 Step:3 Loss:0.4533 Batch Acc:0.8089 Mean Batch Acc:0.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:29<01:15, 37.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 148.0  TN: 116.0  FP: 29.0  FN: 21.0  Precision: 0.8361582  Recall: 0.87573963  F1-score: 0.8554913367767519\n",
      "OVERALL TP: 4915.0  TN: 4412.0  FP: 2144.0  FN: 1403.0  Precision: 0.6962742598101714  Recall: 0.7779360557138335  F1-score: 0.7348433879046125\n",
      "Epoch:7 Step:4 Loss:0.3740 Batch Acc:0.8408 Mean Batch Acc:0.7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [03:07<00:37, 37.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 118.0  TN: 126.0  FP: 52.0  FN: 18.0  Precision: 0.69411767  Recall: 0.86764705  F1-score: 0.77124183854939\n",
      "OVERALL TP: 5033.0  TN: 4538.0  FP: 2196.0  FN: 1421.0  Precision: 0.6962235440586526  Recall: 0.779826464208243  F1-score: 0.7356573850763721\n",
      "Epoch:7 Step:5 Loss:0.4421 Batch Acc:0.7771 Mean Batch Acc:0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 7/10 [24:38<10:42, 214.28s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 129.0  TN: 123.0  FP: 39.0  FN: 23.0  Precision: 0.76785713  Recall: 0.8486842  F1-score: 0.8062499570846569\n",
      "OVERALL TP: 5162.0  TN: 4661.0  FP: 2235.0  FN: 1444.0  Precision: 0.6978504799242936  Recall: 0.781410838631547  F1-score: 0.7372705848746697\n",
      "Epoch:8 Step:0 Loss:0.4087 Batch Acc:0.8025 Mean Batch Acc:0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:35<02:55, 35.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 117.0  TN: 136.0  FP: 39.0  FN: 22.0  Precision: 0.75  Recall: 0.8417266  F1-score: 0.7932203608797539\n",
      "OVERALL TP: 5279.0  TN: 4797.0  FP: 2274.0  FN: 1466.0  Precision: 0.6989275784456508  Recall: 0.7826538176426983  F1-score: 0.7384249545390964\n",
      "Epoch:8 Step:1 Loss:0.4150 Batch Acc:0.8057 Mean Batch Acc:0.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:08<02:18, 34.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 130.0  TN: 115.0  FP: 30.0  FN: 39.0  Precision: 0.8125  Recall: 0.7692308  F1-score: 0.7902735337098636\n",
      "OVERALL TP: 5409.0  TN: 4912.0  FP: 2304.0  FN: 1505.0  Precision: 0.7012835472578763  Recall: 0.7823257159386752  F1-score: 0.7395911670198947\n",
      "Epoch:8 Step:2 Loss:0.4348 Batch Acc:0.7803 Mean Batch Acc:0.7304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:46<01:46, 35.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 131.0  TN: 125.0  FP: 32.0  FN: 26.0  Precision: 0.80368096  Recall: 0.83439493  F1-score: 0.818750029858202\n",
      "OVERALL TP: 5540.0  TN: 5037.0  FP: 2336.0  FN: 1531.0  Precision: 0.7034027425088878  Recall: 0.7834818271814453  F1-score: 0.7412858767645683\n",
      "Epoch:8 Step:3 Loss:0.4393 Batch Acc:0.8153 Mean Batch Acc:0.7323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:23<01:11, 35.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 143.0  TN: 118.0  FP: 27.0  FN: 26.0  Precision: 0.84117645  Recall: 0.84615386  F1-score: 0.843657841241244\n",
      "OVERALL TP: 5683.0  TN: 5155.0  FP: 2363.0  FN: 1557.0  Precision: 0.7063136962465821  Recall: 0.7849447513812154  F1-score: 0.7435561952113043\n",
      "Epoch:8 Step:4 Loss:0.3482 Batch Acc:0.8312 Mean Batch Acc:0.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [03:01<00:36, 36.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 118.0  TN: 131.0  FP: 47.0  FN: 18.0  Precision: 0.7151515  Recall: 0.86764705  F1-score: 0.7840531669604224\n",
      "OVERALL TP: 5801.0  TN: 5286.0  FP: 2410.0  FN: 1575.0  Precision: 0.7064912921690415  Recall: 0.7864696312364425  F1-score: 0.7443382305767626\n",
      "Epoch:8 Step:5 Loss:0.4169 Batch Acc:0.7930 Mean Batch Acc:0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 8/10 [28:17<07:11, 215.59s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 127.0  TN: 129.0  FP: 33.0  FN: 25.0  Precision: 0.79375  Recall: 0.8355263  F1-score: 0.8141025444302881\n",
      "OVERALL TP: 5928.0  TN: 5415.0  FP: 2443.0  FN: 1600.0  Precision: 0.708159120774101  Recall: 0.7874601487778958  F1-score: 0.7457072771872445\n",
      "Epoch:9 Step:0 Loss:0.3875 Batch Acc:0.8153 Mean Batch Acc:0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:36<03:02, 36.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 120.0  TN: 140.0  FP: 35.0  FN: 19.0  Precision: 0.7741935  Recall: 0.8633093  F1-score: 0.8163264752278384\n",
      "OVERALL TP: 6048.0  TN: 5555.0  FP: 2478.0  FN: 1619.0  Precision: 0.7093596059113301  Recall: 0.7888352680318247  F1-score: 0.7469894398814303\n",
      "Epoch:9 Step:1 Loss:0.3954 Batch Acc:0.8280 Mean Batch Acc:0.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:10<02:23, 35.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 133.0  TN: 114.0  FP: 31.0  FN: 36.0  Precision: 0.8109756  Recall: 0.78698224  F1-score: 0.7987987942352854\n",
      "OVERALL TP: 6181.0  TN: 5669.0  FP: 2509.0  FN: 1655.0  Precision: 0.711277330264672  Recall: 0.7887953037263911  F1-score: 0.7480334019121384\n",
      "Epoch:9 Step:2 Loss:0.4100 Batch Acc:0.7866 Mean Batch Acc:0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:46<01:47, 35.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 131.0  TN: 125.0  FP: 32.0  FN: 26.0  Precision: 0.80368096  Recall: 0.83439493  F1-score: 0.818750029858202\n",
      "OVERALL TP: 6312.0  TN: 5794.0  FP: 2541.0  FN: 1681.0  Precision: 0.7129786513046424  Recall: 0.7896909796071563  F1-score: 0.7493767066365902\n",
      "Epoch:9 Step:3 Loss:0.4248 Batch Acc:0.8153 Mean Batch Acc:0.7414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:23<01:12, 36.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 148.0  TN: 118.0  FP: 27.0  FN: 21.0  Precision: 0.8457143  Recall: 0.87573963  F1-score: 0.8604651034208747\n",
      "OVERALL TP: 6460.0  TN: 5912.0  FP: 2568.0  FN: 1702.0  Precision: 0.7155516171909615  Recall: 0.7914726782651311  F1-score: 0.7515997673065736\n",
      "Epoch:9 Step:4 Loss:0.3261 Batch Acc:0.8471 Mean Batch Acc:0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [03:00<00:36, 36.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 122.0  TN: 132.0  FP: 46.0  FN: 14.0  Precision: 0.72619045  Recall: 0.89705884  F1-score: 0.8026315700314374\n",
      "OVERALL TP: 6582.0  TN: 6044.0  FP: 2614.0  FN: 1716.0  Precision: 0.7157459765115267  Recall: 0.7932031814895155  F1-score: 0.7524865668229106\n",
      "Epoch:9 Step:5 Loss:0.4014 Batch Acc:0.8089 Mean Batch Acc:0.7446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 9/10 [31:54<03:36, 216.26s/it]\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 130.0  TN: 130.0  FP: 32.0  FN: 22.0  Precision: 0.80246913  Recall: 0.8552632  F1-score: 0.8280255140467615\n",
      "OVERALL TP: 6712.0  TN: 6174.0  FP: 2646.0  FN: 1738.0  Precision: 0.7172472750587733  Recall: 0.7943195266272189  F1-score: 0.7538185085354896\n",
      "Epoch:10 Step:0 Loss:0.3693 Batch Acc:0.8280 Mean Batch Acc:0.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|██████████████                                                                      | 1/6 [00:36<03:02, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 121.0  TN: 142.0  FP: 33.0  FN: 18.0  Precision: 0.78571427  Recall: 0.8705036  F1-score: 0.8259385901492566\n",
      "OVERALL TP: 6833.0  TN: 6316.0  FP: 2679.0  FN: 1756.0  Precision: 0.7183557611438184  Recall: 0.7955524508091745  F1-score: 0.7549859123805315\n",
      "Epoch:10 Step:1 Loss:0.3788 Batch Acc:0.8376 Mean Batch Acc:0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|████████████████████████████                                                        | 2/6 [01:14<02:27, 36.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 136.0  TN: 116.0  FP: 29.0  FN: 33.0  Precision: 0.8242424  Recall: 0.80473375  F1-score: 0.8143712948199491\n",
      "OVERALL TP: 6969.0  TN: 6432.0  FP: 2708.0  FN: 1789.0  Precision: 0.720161206985636  Recall: 0.7957296186343914  F1-score: 0.7560618388934093\n",
      "Epoch:10 Step:2 Loss:0.3871 Batch Acc:0.8025 Mean Batch Acc:0.7487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 3/6 [01:49<01:49, 36.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 131.0  TN: 126.0  FP: 31.0  FN: 26.0  Precision: 0.80864197  Recall: 0.83439493  F1-score: 0.8213166548004077\n",
      "OVERALL TP: 7100.0  TN: 6558.0  FP: 2739.0  FN: 1815.0  Precision: 0.7216180506148999  Recall: 0.7964105440269209  F1-score: 0.7571718033486189\n",
      "Epoch:10 Step:3 Loss:0.4125 Batch Acc:0.8185 Mean Batch Acc:0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [02:25<01:12, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 150.0  TN: 121.0  FP: 24.0  FN: 19.0  Precision: 0.86206895  Recall: 0.88757396  F1-score: 0.8746355874793632\n",
      "OVERALL TP: 7250.0  TN: 6679.0  FP: 2763.0  FN: 1834.0  Precision: 0.724058723659243  Recall: 0.7981065609863496  F1-score: 0.7592815625490914\n",
      "Epoch:10 Step:4 Loss:0.3092 Batch Acc:0.8631 Mean Batch Acc:0.7519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [03:03<00:36, 36.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 124.0  TN: 134.0  FP: 44.0  FN: 12.0  Precision: 0.7380952  Recall: 0.9117647  F1-score: 0.8157894551919107\n",
      "OVERALL TP: 7374.0  TN: 6813.0  FP: 2807.0  FN: 1846.0  Precision: 0.7242903447598468  Recall: 0.7997830802603036  F1-score: 0.7601670017009432\n",
      "Epoch:10 Step:5 Loss:0.3833 Batch Acc:0.8217 Mean Batch Acc:0.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [35:36<00:00, 217.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: bimpm_lstm\\model_RV.ckpt\n",
      "Testing Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 143.0  TN: 125.0  FP: 31.0  FN: 15.0  Precision: 0.8218391  Recall: 0.9050633  F1-score: 0.8614457817741427\n",
      "OVERALL TP: 143.0  TN: 125.0  FP: 31.0  FN: 15.0  Precision: 0.8218390804597702  Recall: 0.9050632911392406  F1-score: 0.8614457831325303\n",
      "Batch Test Accuracy:0.8535 Mean Batch Test Acc:0.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 1/3 [00:08<00:16,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 146.0  TN: 129.0  FP: 27.0  FN: 12.0  Precision: 0.84393066  Recall: 0.9240506  F1-score: 0.8821752389845824\n",
      "OVERALL TP: 289.0  TN: 254.0  FP: 58.0  FN: 27.0  Precision: 0.8328530259365994  Recall: 0.9145569620253164  F1-score: 0.8717948717948717\n",
      "Batch Test Accuracy:0.8758 Mean Batch Test Acc:0.8646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:16<00:08,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TP: 148.0  TN: 99.0  FP: 43.0  FN: 24.0  Precision: 0.7748691  Recall: 0.8604651  F1-score: 0.815426950243234\n",
      "OVERALL TP: 437.0  TN: 353.0  FP: 101.0  FN: 51.0  Precision: 0.8122676579925651  Recall: 0.8954918032786885  F1-score: 0.8518518518518519\n",
      "Batch Test Accuracy:0.7866 Mean Batch Test Acc:0.8386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:25<00:00,  8.40s/it]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    trained_model = os.path.join('bimpm_lstm', 'model_RV.ckpt')\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(\"bimpm_lstm/\",sess.graph)\n",
    "    print(\"Training...\")\n",
    "    sess.run(tf.global_variables_initializer(), feed_dict={X_init:x.weights})\n",
    "\n",
    "    i = 0.0\n",
    "    sum_acc = 0.0\n",
    "    sum_tp = 0.0\n",
    "    sum_tn = 0.0\n",
    "    sum_fp = 0.0\n",
    "    sum_fn = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(num_epoch)):   #num_epoch\n",
    "\n",
    "        for step in tqdm(range(int(x.sentence_one.shape[0]/batch_size))): \n",
    "\n",
    "            i += 1\n",
    "\n",
    "            batch_s1,batch_s2,batch_y = x.sentence_one[step*batch_size:(step+1)*batch_size],\\\n",
    "                                        x.sentence_two[step*batch_size:(step+1)*batch_size],\\\n",
    "                                        x.y_true[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "            #print batch_s1.shape,batch_s2.shape,batch_y.shape\n",
    "\n",
    "            batch_y = one_hot(batch_size,batch_y.astype(int))\n",
    "\n",
    "#             [summary,_,loss,acc, TP, TN, FP, FN] = sess.run([merged,train_op,loss_op,batch_accuracy, TP, TN, FP, FN],\n",
    "            [summary,_,loss,acc, tp, tn, fp, fn] = sess.run([merged,train_op,loss_op,batch_accuracy, TP, TN, FP, FN],\n",
    "                            feed_dict={X_init:x.weights,\n",
    "                            sentence_one: batch_s1,\n",
    "                            sentence_two: batch_s2,\n",
    "                            Y:batch_y\n",
    "                            })\n",
    "\n",
    "            train_writer.add_summary(summary, i)\n",
    "\n",
    "\n",
    "            sum_acc += acc\n",
    "            \n",
    "            sum_tp += tp\n",
    "            sum_tn += tn\n",
    "            sum_fp += fp\n",
    "            sum_fn += fn\n",
    "                        \n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            \n",
    "            sum_precision = sum_tp / (sum_tp + sum_fp)\n",
    "            sum_recall = sum_tp / (sum_tp + sum_fn)\n",
    "            sum_f1 = 2 * sum_precision * sum_recall / (sum_precision + sum_recall)\n",
    "            \n",
    "            print(\"CURRENT TP:\", tp, \" TN:\", tn, \" FP:\", fp, \" FN:\", fn, \" Precision:\", precision, \" Recall:\", recall, \" F1-score:\", f1)\n",
    "            print(\"OVERALL TP:\", sum_tp, \" TN:\", sum_tn, \" FP:\", sum_fp, \" FN:\", sum_fn, \n",
    "                          \" Precision:\", sum_precision, \" Recall:\", sum_recall, \" F1-score:\", sum_f1)\n",
    "            \n",
    "            print(\"Epoch:\" + str(epoch+1) + \" Step:\" + str(step) + \" Loss:\" + \"{:.4f}\".format(loss) + \" Batch Acc:\" + \"{:.4f}\".format(acc) + \" Mean Batch Acc:\" + \"{:.4f}\".format(sum_acc/i))\n",
    "\n",
    "#             log(\"Epoch:\" + str(epoch+1) + \" Step:\" + str(step) + \" Loss:\" + \"{:.4f}\".format(loss) + \" Batch Acc:\" + \"{:.4f}\".format(acc) + \" Mean Batch Acc:\" + \"{:.4f}\".format(sum_acc/i))\n",
    "\n",
    "    save_path = saver.save(sess, trained_model)\n",
    "    print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "    print(\"Testing Model...\")\n",
    "    i = 0\n",
    "    \n",
    "    sum_acc = 0.0\n",
    "    sum_tp = 0.0\n",
    "    sum_tn = 0.0\n",
    "    sum_fp = 0.0\n",
    "    sum_fn = 0.0\n",
    "    for step in tqdm(range(int(x.sentence_one_test.shape[0]/batch_size))):\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        batch_s1,batch_s2,batch_y = x.sentence_one_test[step*batch_size:(step+1)*batch_size],\\\n",
    "                                    x.sentence_two_test[step*batch_size:(step+1)*batch_size],\\\n",
    "                                    x.y_true_test[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        batch_y = one_hot(batch_size,batch_y.astype(int))\n",
    "\n",
    "#         [acc, TP, TN, FP, FN] = sess.run([batch_accuracy, TP, TN, FP, FN],\n",
    "        [acc, tp, tn, fp, fn] = sess.run([batch_accuracy, TP, TN, FP, FN],\n",
    "                        feed_dict={X_init:x.weights,\n",
    "                        sentence_one: batch_s1,\n",
    "                        sentence_two: batch_s2,\n",
    "                        Y:batch_y\n",
    "                        })\n",
    "        sum_acc += acc\n",
    "        \n",
    "        sum_tp += tp\n",
    "        sum_tn += tn\n",
    "        sum_fp += fp\n",
    "        sum_fn += fn\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        sum_precision = sum_tp / (sum_tp + sum_fp)\n",
    "        sum_recall = sum_tp / (sum_tp + sum_fn)\n",
    "        sum_f1 = 2 * sum_precision * sum_recall / (sum_precision + sum_recall)\n",
    "\n",
    "        print(\"CURRENT TP:\", tp, \" TN:\", tn, \" FP:\", fp, \" FN:\", fn, \" Precision:\", precision, \" Recall:\", recall, \" F1-score:\", f1)\n",
    "        print(\"OVERALL TP:\", sum_tp, \" TN:\", sum_tn, \" FP:\", sum_fp, \" FN:\", sum_fn, \n",
    "                      \" Precision:\", sum_precision, \" Recall:\", sum_recall, \" F1-score:\", sum_f1)\n",
    "\n",
    "        print(\"Batch Test Accuracy:\" + \"{:.4f}\".format(acc) + \" Mean Batch Test Acc:\" + \"{:.4f}\".format(sum_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
